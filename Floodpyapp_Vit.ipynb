{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the model from https://www.dropbox.com/scl/fi/srw7u4cw1gtxrf4xzmsh7/floodvit.pt?rlkey=snskpq1qrdav5u2jya8k2bocg&e=1&dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a modified version of the vit model and upload it in cloud (Google Drive, Dropbox, Zenodo)\n",
    "### Vit pipeline should be differentiated with respect to statistical approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import rioxarray\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import xbatcher\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "vit_model = torch.load('/home/kleanthis/Projects/Thessalia_Floods_2023/Vit_model/floodvit.pt')\n",
    "S1_dataset = xr.open_dataset('/home/kleanthis/Projects/Thessalia_Floods_2023/Preprocessed_20230906T043947/S1_stack_20230906T043947.nc', decode_coords='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "vit_model.to(device)\n",
    "\n",
    "batch_size = 224\n",
    "half_batch_size = int(batch_size/2)\n",
    "\n",
    "data_mean =  [0.0953, 0.0264]\n",
    "data_std = [0.0427, 0.0215]\n",
    "clamp_input = 0.15\n",
    "Normalize = transforms.Normalize(mean=data_mean, std=data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset moved by half batch size\n",
    "S1_dataset_moved_A = S1_dataset.sel(x=slice(S1_dataset.x.isel(x=56).data,S1_dataset.x.isel(x=-1).data),\n",
    "                                 y=slice(S1_dataset.y.isel(y=56).data,S1_dataset.y.isel(y=-1).data))\n",
    "\n",
    "S1_dataset_moved_B = S1_dataset.sel(x=slice(S1_dataset.x.isel(x=112).data,S1_dataset.x.isel(x=-1).data),\n",
    "                                 y=slice(S1_dataset.y.isel(y=112).data,S1_dataset.y.isel(y=-1).data))\n",
    "\n",
    "S1_dataset_moved_C = S1_dataset.sel(x=slice(S1_dataset.x.isel(x=168).data,S1_dataset.x.isel(x=-1).data),\n",
    "                                 y=slice(S1_dataset.y.isel(y=168).data,S1_dataset.y.isel(y=-1).data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:23<00:00, 17.25it/s]\n",
      "100%|██████████| 375/375 [00:22<00:00, 17.01it/s]\n",
      "100%|██████████| 375/375 [00:21<00:00, 17.55it/s]\n",
      "100%|██████████| 360/360 [00:21<00:00, 17.08it/s]\n"
     ]
    }
   ],
   "source": [
    "prediction_xarrays_list = []\n",
    "for xr_dataset in [S1_dataset, S1_dataset_moved_A, S1_dataset_moved_B, S1_dataset_moved_C]:\n",
    "    predictions_batches_list = []\n",
    "    post_bgen = xbatcher.BatchGenerator(xr_dataset.sel(time='2023-09-06T04:39:47.000000000'), input_dims = {'x': batch_size, 'y': batch_size})\n",
    "    pre1_bgen = xbatcher.BatchGenerator(xr_dataset.sel(time='2023-08-01T04:39:57.000000000'), input_dims = {'x': batch_size, 'y': batch_size})\n",
    "    pre2_bgen = xbatcher.BatchGenerator(xr_dataset.sel(time='2023-08-13T04:39:57.000000000'), input_dims = {'x': batch_size, 'y': batch_size})\n",
    "\n",
    "    for patch_i in tqdm(range(len(post_bgen))):\n",
    "\n",
    "        post_dB = np.stack([post_bgen[patch_i].VV_dB.values, post_bgen[patch_i].VH_dB.values],axis=0)\n",
    "        post = np.power(10, post_dB/10) # convert to linear\n",
    "\n",
    "        pre1_dB = np.stack([pre1_bgen[patch_i].VV_dB.values, pre1_bgen[patch_i].VH_dB.values],axis=0)\n",
    "        pre1 = np.power(10, pre1_dB/10) # convert to linear\n",
    "\n",
    "        pre2_dB = np.stack([pre2_bgen[patch_i].VV_dB.values, pre2_bgen[patch_i].VH_dB.values],axis=0)\n",
    "        pre2 = np.power(10, pre2_dB/10) # convert to linear\n",
    "\n",
    "        post = torch.clamp(torch.from_numpy(post).float(), min=0.0, max=clamp_input)\n",
    "        post = torch.nan_to_num(post,clamp_input)\n",
    "        pre1 = torch.clamp(torch.from_numpy(pre1).float(), min=0.0, max=clamp_input)\n",
    "        pre1 = torch.nan_to_num(pre1,clamp_input)\n",
    "        pre2 = torch.clamp(torch.from_numpy(pre2).float(), min=0.0, max=clamp_input)\n",
    "        pre2 = torch.nan_to_num(pre2,clamp_input)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=False):\n",
    "            with torch.no_grad():\n",
    "                post_event = Normalize(post).to(device).unsqueeze(0)\n",
    "                pre_event_1 = Normalize(pre1).to(device).unsqueeze(0)\n",
    "                pre_event_2 = Normalize(pre2).to(device).unsqueeze(0)\n",
    "\n",
    "                pre_event_1 = pre_event_1.to(device)\n",
    "                post_event = torch.cat((post_event, pre_event_1), dim=1)\n",
    "                post_event = torch.cat((post_event, pre_event_2.to(device)), dim=1)\n",
    "                output = vit_model(post_event)\n",
    "\n",
    "                predictions = output.argmax(1)\n",
    "\n",
    "        prediction_data = np.squeeze(predictions.to('cpu').numpy())\n",
    "\n",
    "        prediction_patch_xarray = xr.Dataset({'flood_vit': ([\"y\",\"x\"], prediction_data)},\n",
    "                                            coords={\n",
    "                                                    \"x\": ([\"x\"], post_bgen[patch_i].x.data),\n",
    "                                                    \"y\": ([\"y\"], post_bgen[patch_i].y.data),\n",
    "                                            },\n",
    "                                            )\n",
    "        prediction_patch_xarray.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "        predictions_batches_list.append(prediction_patch_xarray)\n",
    "\n",
    "    prediction_xarrays_list.append(xr.combine_by_coords(predictions_batches_list))\n",
    "\n",
    "# vit_flooded_regions = xr.merge(prediction_xarrays_list, compat='override')\n",
    "# vit_flooded_regions.x.attrs['standard_name'] = 'X'\n",
    "# vit_flooded_regions.x.attrs['long_name'] = 'Coordinate X'\n",
    "# vit_flooded_regions.x.attrs['units'] = 'degrees'\n",
    "# vit_flooded_regions.x.attrs['axis'] = 'X'\n",
    "\n",
    "# vit_flooded_regions.y.attrs['standard_name'] = 'Y'\n",
    "# vit_flooded_regions.y.attrs['long_name'] = 'Coordinate Y'\n",
    "# vit_flooded_regions.y.attrs['units'] = 'degrees'\n",
    "# vit_flooded_regions.y.attrs['axis'] = 'Y'\n",
    "# vit_flooded_regions.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "\n",
    "# vit_flooded_regions.to_netcdf('/home/kleanthis/Projects/Thessalia_Floods_2023/Results/Flood_vit.nc', format='NETCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pixel_disp in enumerate([0,56,112, 168]):\n",
    "    vit_flooded_regions = prediction_xarrays_list[i]\n",
    "    vit_flooded_regions.x.attrs['standard_name'] = 'X'\n",
    "    vit_flooded_regions.x.attrs['long_name'] = 'Coordinate X'\n",
    "    vit_flooded_regions.x.attrs['units'] = 'degrees'\n",
    "    vit_flooded_regions.x.attrs['axis'] = 'X'\n",
    "\n",
    "    vit_flooded_regions.y.attrs['standard_name'] = 'Y'\n",
    "    vit_flooded_regions.y.attrs['long_name'] = 'Coordinate Y'\n",
    "    vit_flooded_regions.y.attrs['units'] = 'degrees'\n",
    "    vit_flooded_regions.y.attrs['axis'] = 'Y'\n",
    "    vit_flooded_regions.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "\n",
    "    vit_flooded_regions.to_netcdf('/home/kleanthis/Projects/Thessalia_Floods_2023/Results/Flood_vit_{}.nc'.format(pixel_disp), format='NETCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
